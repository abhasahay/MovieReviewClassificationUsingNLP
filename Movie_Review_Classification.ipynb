{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classification of Movie Reviews as positive or Negative\n",
    "\n",
    "import nltk\n",
    "import random \n",
    "from nltk.corpus import movie_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 2000\n",
      "First Review: ([u'long', u'time', u'buddies', u'and', u'neil', u'diamond', u'tribute', u'band', u'members', u'wayne', u'(', u'steve', u'zahn', u',', u'\"', u'happy', u',', u'texas', u'\"', u')', u'and', u'j', u'.', u'd', u'.', u'(', u'jack', u'black', u',', u'\"', u'high', u'fidelity', u'\"', u')', u'watch', u'in', u'horror', u'as', u'third', u'mate', u'darren', u'silverman', u'(', u'jason', u'biggs', u',', u'\"', u'american', u'pie', u'\"', u')', u'disappears', u'under', u'the', u'thumb', u'of', u'his', u'new', u'fiance', u'judith', u',', u'(', u'amanda', u'peet', u',', u'\"', u'the', u'whole', u'nine', u'yards', u'\"', u')', u'a', u'controlling', u'psychiatrist', u'.', u'they', u\"'\", u're', u'doubly', u'troubled', u'when', u'the', u'return', u'of', u'darren', u\"'\", u's', u\"'\", u'one', u'and', u'only', u'love', u\"'\", u'sandy', u'perkins', u'(', u'amanda', u'detmer', u',', u'\"', u'final', u'destination', u'\"', u')', u'returns', u'to', u'their', u'home', u'town', u'but', u'doesn', u\"'\", u't', u'cause', u'a', u'ripple', u'in', u'darren', u\"'\", u's', u'devotion', u'to', u'judith', u'.', u'there', u\"'\", u's', u'only', u'one', u'thing', u'wayne', u'and', u'j', u'.', u'd', u'.', u'can', u'think', u'of', u'doing', u'-', u'they', u'kidnap', u'judith', u'and', u'fake', u'her', u'death', u'in', u'\"', u'saving', u'silverman', u'.', u'\"', u'written', u'by', u'hank', u'nelken', u'and', u'greg', u'depaul', u'after', u'seeing', u'a', u'friend', u'engaged', u'to', u'the', u'wrong', u'woman', u',', u'\"', u'saving', u'silverman', u'\"', u'is', u'directed', u'by', u\"'\", u'hit', u'comedy', u'director', u\"'\", u'dennis', u'dugan', u'of', u'such', u'films', u'as', u'\"', u'big', u'daddy', u',', u'\"', u'\"', u'brain', u'donors', u'\"', u'and', u'\"', u'problem', u'child', u'.', u'\"', u'it', u\"'\", u's', u'a', u'dismal', u',', u'third', u'-', u'rate', u'farrelly', u'brothers', u'rip', u'off', u'that', u'attempts', u'to', u'milk', u'humor', u'from', u'such', u'inspired', u'bits', u'of', u'whimsy', u'as', u'having', u'darren', u\"'\", u's', u'love', u'interest', u'come', u'from', u'a', u'family', u'of', u'circus', u'freaks', u'and', u'be', u'about', u'to', u'become', u'a', u'nun', u'.', u'gross', u'out', u'gags', u'include', u'a', u'visualization', u'of', u'darren', u'getting', u'butt', u'cheek', u'implants', u'.', u'\"', u'saving', u'silverman', u'\"', u'is', u'almost', u'saved', u'by', u'stars', u'zahn', u'and', u'black', u'.', u'these', u'two', u'are', u'so', u'comically', u'talented', u'they', u'can', u'take', u'bad', u'material', u'and', u'still', u'deliver', u'the', u'goods', u'.', u'they', u\"'\", u're', u'in', u'\"', u'animal', u'house', u'\"', u'mode', u'while', u'the', u'rest', u'of', u'the', u'film', u'trawls', u'along', u'and', u'comes', u'up', u'empty', u'.', u'jason', u'biggs', u'can', u'attribute', u'his', u'entire', u'career', u'to', u'the', u'luck', u'of', u'having', u'been', u'cast', u'in', u'the', u'smash', u'hit', u'\"', u'american', u'pie', u'.', u'\"', u'peet', u'shows', u'some', u'physical', u'moves', u'but', u'no', u'flair', u'for', u'comedy', u'here', u'while', u'detmer', u'slaps', u'a', u'brave', u',', u'sweet', u'smile', u'onto', u'her', u'face', u'and', u'soldiers', u'through', u'.', u'r', u'.', u'lee', u'ermey', u'(', u'\"', u'full', u'metal', u'jacket', u'\"', u')', u'is', u'one', u'note', u'in', u'an', u'embarrassing', u'performance', u'as', u'a', u'psychopathic', u'ex', u'-', u'football', u'coach', u'.', u'neil', u'diamond', u'appears', u'at', u'the', u'film', u\"'\", u's', u'climax', u'as', u'himself', u'and', u'miraculously', u'enlivens', u'the', u'proceedings', u'by', u'belting', u'out', u'some', u'of', u'his', u'old', u'standards', u'.'], u'neg')\n",
      "Most common words: [(u',', 77717), (u'the', 76529), (u'.', 65876), (u'a', 38106), (u'and', 35576), (u'of', 34123), (u'to', 31937), (u\"'\", 30585), (u'is', 25195), (u'in', 21822), (u's', 18513), (u'\"', 17612), (u'it', 16107), (u'that', 15924), (u'-', 15595)]\n",
      "The word happy: 215\n"
     ]
    }
   ],
   "source": [
    "# build list of documents\n",
    "documents =[(list(movie_reviews.words(fileid)),category)\n",
    "           for category in movie_reviews.categories()\n",
    "           for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "#shuffle documents\n",
    "random.shuffle(documents)\n",
    "\n",
    "print('Number of Documents: {}'.format(len(documents)))\n",
    "print('First Review: {}'.format(documents[0]))\n",
    "\n",
    "all_words=[]\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "    \n",
    "all_words=nltk.FreqDist(all_words)\n",
    "\n",
    "print('Most common words: {}'.format(all_words.most_common(15)))\n",
    "print('The word happy: {}'.format(all_words[\"happy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39768\n"
     ]
    }
   ],
   "source": [
    "print(len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll use 4000 most common words as features\n",
    "\n",
    "word_features = list(all_words.keys())[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shows\n",
      "kids\n",
      "plot\n",
      "music\n",
      "want\n",
      "production\n",
      "feeling\n",
      "away\n",
      ".\n",
      "has\n",
      "confusing\n",
      "bottom\n",
      "exact\n",
      "years\n",
      "still\n",
      "now\n",
      "didn\n",
      "one\n",
      "s\n",
      "world\n",
      "arrow\n",
      "with\n",
      "concept\n",
      "7\n",
      "horror\n",
      "more\n",
      "visions\n",
      "american\n",
      "feels\n",
      "also\n",
      "into\n",
      "video\n",
      "makes\n",
      "start\n",
      "tons\n",
      "despite\n",
      "meantime\n",
      "'\n",
      "insight\n",
      "off\n",
      "not\n",
      "wes\n",
      "problem\n"
     ]
    }
   ],
   "source": [
    "# Build a find features function that detrmines which of the 4000 word features are present in a review\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features= {}\n",
    "    \n",
    "    for w in word_features:\n",
    "        features[w]=(w in words)\n",
    "    return features\n",
    "    \n",
    "# Using example from negative review\n",
    "features= find_features(movie_reviews.words('neg/cv000_29416.txt'))\n",
    "\n",
    "for key,value in features.items():\n",
    "    if value==True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Features of all documents\n",
    "featuresets=[(find_features(rev),category) for (rev,category) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can split the featuresets into training and test sets using sklearn\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Defind seed for reproducibility\n",
    "seed=1\n",
    "\n",
    "#Splitting data\n",
    "\n",
    "training, testing =model_selection.train_test_split(featuresets,test_size=0.25,random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "print(len(training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How we use skleanr algos in nltk\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SklearnClassifier(BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on training data\n",
    "\n",
    "model.train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy :0.702\n"
     ]
    }
   ],
   "source": [
    "# Test on testing dataset\n",
    "accuracy =nltk.classify.accuracy(model,testing)\n",
    "print('Bernoulli Accuracy :{}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
